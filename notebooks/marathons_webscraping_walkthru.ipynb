{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping class walk-through, to scrape information from Rock and Roll Marathons\n",
    "#### This notebook is to scrape the data from ONE PAGE of the Marathons website, to learn Requests, and BeautifulSoup\n",
    "#### For my personal work, two other notebooks will be created:\n",
    "- marathons_webscraping, to scrape the data and create .csv files\n",
    "- marathons_EDA (Exploratory Data Analysis), to analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's a good idea to view the page source first, of the web page(s) you intend to scrape, to see how it's structured\n",
    "- The devtools may also be helpful\n",
    "    - In Chrome right-click and choose `inspect` or just use `F12` to bring up the devtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of pages of results for each race. \n",
    "#From Readme file for class assignment (instructors got this info by using Postman app)\n",
    "#Need this info to build the loop and function later (in personal work) when build \n",
    "#function / for loop.\n",
    "\n",
    "pgs_2016 = 154   \n",
    "pgs_2017 = 147   \n",
    "pgs_2018 = 85   \n",
    "pgs_2019 = 113   \n",
    "pgs_half_2016 = 898   \n",
    "pgs_half_2017 = 892   \n",
    "pgs_half_2018 = 598   \n",
    "pgs_half_2019 = 690   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlbase_2019 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2019-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_2018 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2018-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_2017 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2017-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_2016 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2016-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2019 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2019-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2018 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2018-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2017 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2017-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2016 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2016-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The steps to get a DataFrame from one page of results look like this:\n",
    "1. Build a URL by combining the base url with a specific page number\n",
    "2. Use requests.post() to get the results of the post\n",
    "3. Make a soup from results.text\n",
    "4. Look at the soup to identify the table you want based on one of its attributes (like class) \n",
    "5. Pass the table as a string to pandas read_html() \n",
    "6. What does that look like? What is the datatype?\n",
    "7. Keep working with the data until you have it a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2019-Results?gender=&agegroup=&bib=&firstname=&lastname=&page=99\n"
     ]
    }
   ],
   "source": [
    "#STEP 1: Build a URL by combining the base url with a specific page number\n",
    "'''QUESTION: Why is this needed? \n",
    "    Could you do base = 'https://www.runrocknroll.com/Events/...[full web address]?\n",
    "    Why is url = base + str(99) needed?\n",
    "    '''\n",
    "\n",
    "base = urlbase_2019\n",
    "page = 99             #To pull just one page to take a look at \n",
    "url = base + str(99)  #This appends page #99 to the end of the URL. \n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a request using the `requests` [library](https://requests.readthedocs.io/en/master/user/quickstart/)\n",
    "- `request.get()` uses http GET to get a webpage\n",
    "- `request.post()` uses http POST when the webpage is submitting a form\n",
    "- checking the [`status_code`](https://www.restapitutorial.com/httpstatuscodes.html) on the result let's you know your request was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "#STEP 2: Use requests.post() to get the results of the post\n",
    "\n",
    "'''QUESTION: I don't understand what \"requests.post\" is. What's happening here?\n",
    "What does it mean in the 2nd bullet above \"when the webpage is submitting a form\"?\n",
    "Doest that just mean the webpage has a form on it that people are filling out?\n",
    "\n",
    "Why is response.TEXT needed in line 11 below?'''\n",
    "\n",
    "response = requests.post(url)   #url defined above, it's page 99 (only) of 2019 full marathon.\n",
    "print(type(response))           #To see what type \"response\" is. It's requests.\n",
    "soup = BS(response.text, 'lxml')   #parses response (page 99 of 2019 full marathon) into a soup\n",
    "print(type(soup))               #To see what type \"soup\" is. It's a Beautiful Soup class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Make a soup from response.text (which is generated above by requests.post(url)\n",
    "#         This is telling soup to find all attributes for below type of table\n",
    "\n",
    "tables = soup.find_all('table',\n",
    "                  attrs = {'class': 'table table-responsive table-bordered'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 4: Look at the soup to identify the table you want \n",
    "#        based on one of its attributes (like class)\n",
    "\n",
    "#This looks at the number of tables, from the original \n",
    "#home page - we can deduce that it's the top \"search\" table, \n",
    "#plus leaderboards for females, males.\n",
    "\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: Pass the table as a string to pandas read_html()\n",
    "\n",
    "#We can deduce that the first table is the one we want (position 0)\n",
    "#This code returns a LIST of the DATAFRAMES.. we're only asking for the one in position [0], \n",
    "#  so we'll just get one df.\n",
    "#OPTIONS: Could save each df and append to 0, or save several small dfs then append that.\n",
    "#Doing little dfs helps see what's going on by using print().\n",
    "\n",
    "results_list = pd.read_html(str(tables[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirmed that we just got 1 table back. \n",
    "\n",
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_list[0]  #gets the first (only) df from the results_list created in STEP 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overall     int64\n",
       "Bib         int64\n",
       "Name       object\n",
       "Time       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 6: What does that look like? What is the datatype?\n",
    "#STEP 7: Keep working with the data until you have it a DataFrame\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Bib</th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99999</td>\n",
       "      <td>32379</td>\n",
       "      <td>Raquel Flores</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99999</td>\n",
       "      <td>30292</td>\n",
       "      <td>Kyle Domingos</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99999</td>\n",
       "      <td>32850</td>\n",
       "      <td>Paul Dillard</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99999</td>\n",
       "      <td>31415</td>\n",
       "      <td>Nicole Bennett</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99999</td>\n",
       "      <td>32995</td>\n",
       "      <td>Rudy Novak</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Overall    Bib            Name      Time\n",
       "0    99999  32379   Raquel Flores  00:00:00\n",
       "1    99999  30292   Kyle Domingos  00:00:00\n",
       "2    99999  32850    Paul Dillard  00:00:00\n",
       "3    99999  31415  Nicole Bennett  00:00:00\n",
       "4    99999  32995      Rudy Novak  00:00:00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Yup, looking good. (Zero times are for people who didn't finish in alloted time)\n",
    "\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the start of the next part... may not need this code.\n",
    "pd.read_html(str(tables[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
